{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d8d793",
   "metadata": {},
   "source": [
    "Dataset: trec06p\n",
    "Programming Language: Python 3.9.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21196489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ab4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.unzip import unzip_no_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd02e7",
   "metadata": {},
   "source": [
    "Part of the machine learning process is processing data to a format suitable for analysis and training. In this part, we start by loading the zip file contents and creation of an initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf6b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_no_pass(path, out_path):\n",
    "    '''\n",
    "    Extracts all contents of a zip file without a password.\n",
    "    \n",
    "    Args:\n",
    "        path:\n",
    "            (str) path to zip file to extract.\n",
    "        out_path:\n",
    "            (str) path to directory to store the extracted contents.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # make sure out path directory existsge\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(path, 'r') as file:\n",
    "        file.extractall(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb56f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.unzip import unzip_no_pass\n",
    "\n",
    "# create dataframe from spam filtering dataset\n",
    "def create_dataframe(path_to_zip, \n",
    "                     out_path=\"./data/spam_filter\", \n",
    "                     unzip=False,\n",
    "                     save_ext=\"csv\"\n",
    "                    ):\n",
    "    \n",
    "    assert save_ext in [\"csv\", \"parquet\"], \"Extensions allowed are csv and parquet.\"\n",
    "    \n",
    "    path_to_zip = os.path.normpath(path_to_zip)\n",
    "    out_path = os.path.normpath(out_path)\n",
    "    \n",
    "    # unzip file first\n",
    "    if unzip:\n",
    "        unzip_no_pass(path=path_to_zip, out_path=out_path)\n",
    "    \n",
    "    filename = os.path.basename(path_to_zip).split(\".\")[0]\n",
    "    \n",
    "    #start of processing unzipped files\n",
    "    df = pd.read_csv(os.path.join(out_path, filename, \"labels\"), sep=\"/\", header=None)\n",
    "    \n",
    "    # clean dataframe\n",
    "    # initial columns are 0, 1, 2, 3\n",
    "    df[0] = df[0].str.replace(\" ..\", \"\") # labels has extra artifacts\n",
    "    df = df.drop(columns=1) # drop unnecessary column\n",
    "    df = df.rename(columns = {0 : \"Class\", 2 : \"Folder\", 3: \"File\"}) # rename\n",
    "    \n",
    "    # replace spam and ham values\n",
    "    df[\"Class\"] = df[\"Class\"].replace({\"ham\" : 0, \"spam\" : 1})\n",
    "    \n",
    "    # combine with text / email data\n",
    "    for i in range(len(df)):\n",
    "        folder_id = \"{0:0=3d}\".format(df.at[i,'Folder'])\n",
    "        file_id = \"{0:0=3d}\".format(df.at[i,'File'])\n",
    "        \n",
    "        path = os.path.normpath(os.path.join(out_path, filename, \"data\", folder_id, file_id))\n",
    "        \n",
    "        # there will be an error if utf-8 is used as encoding\n",
    "        df.at[i, \"Email\"] = open(path, encoding=\"latin1\").read()\n",
    "        \n",
    "    df[\"Email\"] = df[\"Email\"].str.lower()\n",
    "\n",
    "    if save_ext == \"csv\":\n",
    "        df.to_csv(os.path.join(out_path, f\"{filename}.{save_ext}\"), index=False)\n",
    "    elif save_ext == \"parquet\":\n",
    "        df.to_parquet(os.path.join(out_path, f\"{filename}.{save_ext}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c2fe1",
   "metadata": {},
   "source": [
    "Run creation of dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8909c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phrungck\\AppData\\Local\\Temp\\ipykernel_5616\\710491051.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"Class\"] = df[\"Class\"].replace({\"ham\" : 0, \"spam\" : 1})\n"
     ]
    }
   ],
   "source": [
    "create_dataframe(path_to_zip=\"./data/trec06p-cs280.zip\", unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96426d33",
   "metadata": {},
   "source": [
    "Loading processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aded30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/spam_filter/trec06p-cs280.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c4728",
   "metadata": {},
   "source": [
    "In this work, no class balancing techniques will be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782fff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    0.658664\n",
       "0    0.341336\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8ccfc",
   "metadata": {},
   "source": [
    "The above probabilities are the spam and ham priori respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e9996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>received: from rodan.uu.net by aramis.rutgers....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>received: from unknown (helo groucho.cs.psu.ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>received: from psuvax1.cs.psu.edu ([130.203.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>received: from 201-1-198-159.dsl.telesp.net.br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>17</td>\n",
       "      <td>received: from ?211.200.1.51? (unknown [211.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>18</td>\n",
       "      <td>received:\\n\\tfrom dsl.dynamic212156187251.ttne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>19</td>\n",
       "      <td>received: from wonder.hananet.net (unknown [21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>20</td>\n",
       "      <td>received: from mail.csonline.com (unknown [61....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>21</td>\n",
       "      <td>received: from 3f9cfcb8 (201-43-166-100.dsl.te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class  Folder  File                                              Email\n",
       "0          0       0     0  received: from rodan.uu.net by aramis.rutgers....\n",
       "1          1       0     1  received: from unknown (helo groucho.cs.psu.ed...\n",
       "2          1       0     2  received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...\n",
       "3          0       0     3  received: from psuvax1.cs.psu.edu ([130.203.2....\n",
       "4          1       0     4  received: from 201-1-198-159.dsl.telesp.net.br...\n",
       "...      ...     ...   ...                                                ...\n",
       "37817      1     126    17  received: from ?211.200.1.51? (unknown [211.20...\n",
       "37818      1     126    18  received:\\n\\tfrom dsl.dynamic212156187251.ttne...\n",
       "37819      1     126    19  received: from wonder.hananet.net (unknown [21...\n",
       "37820      1     126    20  received: from mail.csonline.com (unknown [61....\n",
       "37821      1     126    21  received: from 3f9cfcb8 (201-43-166-100.dsl.te...\n",
       "\n",
       "[37822 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a553291",
   "metadata": {},
   "source": [
    "The dataset is composed of 66% spam and 34% ham. \n",
    "\n",
    "We now construct the vocabulary. In constructing the vocabulary, we limit our definition of a word to a sequence of alphabetic characters delimited by a white space, comma, and period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099e3ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_vocab(arr, pattern=r'\\b[a-zA-Z]+\\b'):\n",
    "    # empty array to store vocabulary\n",
    "    vocab = []\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        vocab += re.findall(pattern, arr[i])\n",
    "        \n",
    "    return vocab # list of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4194998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18280478"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = create_vocab(df[\"Email\"].values)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463e79cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['received',\n",
       " 'from',\n",
       " 'rodan',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'by',\n",
       " 'aramis',\n",
       " 'rutgers',\n",
       " 'edu',\n",
       " 'id',\n",
       " 'mon',\n",
       " 'jul',\n",
       " 'edt',\n",
       " 'received',\n",
       " 'from',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'by',\n",
       " 'rodan',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'uunet',\n",
       " 'mail',\n",
       " 'drop',\n",
       " 'id',\n",
       " 'mon',\n",
       " 'jul',\n",
       " 'received',\n",
       " 'from',\n",
       " 'uunet',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'via',\n",
       " 'localhost',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'by',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'uunet',\n",
       " 'internet',\n",
       " 'primary',\n",
       " 'id',\n",
       " 'mon',\n",
       " 'jul',\n",
       " 'received',\n",
       " 'from',\n",
       " 'sarto',\n",
       " 'uucp',\n",
       " 'by',\n",
       " 'uunet',\n",
       " 'uu',\n",
       " 'net',\n",
       " 'with',\n",
       " 'uucp',\n",
       " 'rmail',\n",
       " 'queueing',\n",
       " 'rmail',\n",
       " 'id',\n",
       " 'mon',\n",
       " 'jul',\n",
       " 'edt',\n",
       " 'newsgroups',\n",
       " 'soc',\n",
       " 'religion',\n",
       " 'christian',\n",
       " 'path',\n",
       " 'jhpb',\n",
       " 'from',\n",
       " 'jhpb',\n",
       " 'sarto',\n",
       " 'budd',\n",
       " 'lake',\n",
       " 'nj',\n",
       " 'us',\n",
       " 'joseph',\n",
       " 'h',\n",
       " 'buehler',\n",
       " 'subject',\n",
       " 'new',\n",
       " 'catholic',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'now',\n",
       " 'up',\n",
       " 'and',\n",
       " 'running',\n",
       " 'message',\n",
       " 'id',\n",
       " 'jhpb',\n",
       " 'sarto',\n",
       " 'budd',\n",
       " 'lake',\n",
       " 'nj',\n",
       " 'us',\n",
       " 'sender',\n",
       " 'jhpb',\n",
       " 'sarto',\n",
       " 'budd',\n",
       " 'lake',\n",
       " 'nj',\n",
       " 'us',\n",
       " 'joseph',\n",
       " 'h',\n",
       " 'buehler',\n",
       " 'organization',\n",
       " 'none',\n",
       " 'date',\n",
       " 'tue',\n",
       " 'jul',\n",
       " 'gmt',\n",
       " 'content',\n",
       " 'type',\n",
       " 'text',\n",
       " 'content',\n",
       " 'length',\n",
       " 'apparently',\n",
       " 'to',\n",
       " 'soc',\n",
       " 'religion',\n",
       " 'christian',\n",
       " 'the',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'i',\n",
       " 'queried',\n",
       " 'about',\n",
       " 'a',\n",
       " 'few',\n",
       " 'weeks',\n",
       " 'ago',\n",
       " 'is',\n",
       " 'now',\n",
       " 'up',\n",
       " 'and',\n",
       " 'running',\n",
       " 'i',\n",
       " 'have',\n",
       " 'also',\n",
       " 'set',\n",
       " 'up',\n",
       " 'an',\n",
       " 'archive',\n",
       " 'server',\n",
       " 'see',\n",
       " 'below',\n",
       " 'the',\n",
       " 'following',\n",
       " 'is',\n",
       " 'the',\n",
       " 'official',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'list',\n",
       " 'message',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'joe',\n",
       " 'buehler',\n",
       " 'this',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'is',\n",
       " 'for',\n",
       " 'people',\n",
       " 'who',\n",
       " 'desire',\n",
       " 'serious',\n",
       " 'orthodox',\n",
       " 'discussion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'roman',\n",
       " 'catholic',\n",
       " 'religion',\n",
       " 'i',\n",
       " 'assume',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'cater',\n",
       " 'mainly',\n",
       " 'to',\n",
       " 'catholics',\n",
       " 'but',\n",
       " 'everyone',\n",
       " 'else',\n",
       " 'is',\n",
       " 'welcome',\n",
       " 'provided',\n",
       " 'they',\n",
       " 'operate',\n",
       " 'within',\n",
       " 'the',\n",
       " 'below',\n",
       " 'guidelines',\n",
       " 'my',\n",
       " 'own',\n",
       " 'interests',\n",
       " 'have',\n",
       " 'a',\n",
       " 'doctrinal',\n",
       " 'bent',\n",
       " 'but',\n",
       " 'i',\n",
       " 'm',\n",
       " 'certainly',\n",
       " 'not',\n",
       " 'going',\n",
       " 'to',\n",
       " 'limit',\n",
       " 'this',\n",
       " 'list',\n",
       " 'to',\n",
       " 'just',\n",
       " 'that',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'discussion',\n",
       " 'having',\n",
       " 'participated',\n",
       " 'in',\n",
       " 'usenet',\n",
       " 'religion',\n",
       " 'groups',\n",
       " 'for',\n",
       " 'about',\n",
       " 'years',\n",
       " 'now',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'primary',\n",
       " 'observations',\n",
       " 'about',\n",
       " 'catholics',\n",
       " 'on',\n",
       " 'the',\n",
       " 'net',\n",
       " 'is',\n",
       " 'that',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'know',\n",
       " 'their',\n",
       " 'religion',\n",
       " 'very',\n",
       " 'well',\n",
       " 'my',\n",
       " 'hope',\n",
       " 'is',\n",
       " 'that',\n",
       " 'this',\n",
       " 'list',\n",
       " 'might',\n",
       " 'help',\n",
       " 'remedy',\n",
       " 'this',\n",
       " 'problem',\n",
       " 'to',\n",
       " 'some',\n",
       " 'extent',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'a',\n",
       " 'net',\n",
       " 'resource',\n",
       " 'available',\n",
       " 'for',\n",
       " 'catholics',\n",
       " 'who',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'more',\n",
       " 'about',\n",
       " 'their',\n",
       " 'religion',\n",
       " 'as',\n",
       " 'far',\n",
       " 'as',\n",
       " 'moderation',\n",
       " 'policy',\n",
       " 'goes',\n",
       " 'the',\n",
       " 'catholic',\n",
       " 'church',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'democracy',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'monarchy',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'a',\n",
       " 'divinely',\n",
       " 'given',\n",
       " 'constitution',\n",
       " 'i',\n",
       " 'don',\n",
       " 't',\n",
       " 'set',\n",
       " 'the',\n",
       " 'rules',\n",
       " 'in',\n",
       " 'the',\n",
       " 'church',\n",
       " 'neither',\n",
       " 'does',\n",
       " 'my',\n",
       " 'parish',\n",
       " 'priest',\n",
       " 'nor',\n",
       " 'does',\n",
       " 'my',\n",
       " 'bishop',\n",
       " 'nor',\n",
       " 'does',\n",
       " 'the',\n",
       " 'pope',\n",
       " 'everyone',\n",
       " 'has',\n",
       " 'to',\n",
       " 'adhere',\n",
       " 'to',\n",
       " 'the',\n",
       " 'way',\n",
       " 'christ',\n",
       " 'set',\n",
       " 'things',\n",
       " 'up',\n",
       " 'i',\n",
       " 'think',\n",
       " 'it',\n",
       " 'follows',\n",
       " 'that',\n",
       " 'it',\n",
       " 's',\n",
       " 'not',\n",
       " 'really',\n",
       " 'appropriate',\n",
       " 'for',\n",
       " 'someone',\n",
       " 'to',\n",
       " 'call',\n",
       " 'himself',\n",
       " 'a',\n",
       " 'catholic',\n",
       " 'and',\n",
       " 'argue',\n",
       " 'with',\n",
       " 'this',\n",
       " 'state',\n",
       " 'of',\n",
       " 'affairs',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'catholic',\n",
       " 'it',\n",
       " 's',\n",
       " 'simple',\n",
       " 'enough',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'of',\n",
       " 'the',\n",
       " 'church',\n",
       " 'the',\n",
       " 'moderation',\n",
       " 'policy',\n",
       " 'will',\n",
       " 'reflect',\n",
       " 'this',\n",
       " 'way',\n",
       " 'of',\n",
       " 'thinking',\n",
       " 'there',\n",
       " 'are',\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'other',\n",
       " 'places',\n",
       " 'on',\n",
       " 'the',\n",
       " 'net',\n",
       " 'where',\n",
       " 'catholic',\n",
       " 'doctrine',\n",
       " 'can',\n",
       " 'be',\n",
       " 'freely',\n",
       " 'attacked',\n",
       " 'if',\n",
       " 'in',\n",
       " 'doubt',\n",
       " 'you',\n",
       " 'can',\n",
       " 'always',\n",
       " 'subscribe',\n",
       " 'and',\n",
       " 'see',\n",
       " 'whether',\n",
       " 'the',\n",
       " 'list',\n",
       " 'is',\n",
       " 'to',\n",
       " 'your',\n",
       " 'taste',\n",
       " 'besides',\n",
       " 'the',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'few',\n",
       " 'other',\n",
       " 'things',\n",
       " 'that',\n",
       " 'may',\n",
       " 'be',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'i',\n",
       " 'have',\n",
       " 'set',\n",
       " 'up',\n",
       " 'an',\n",
       " 'archive',\n",
       " 'server',\n",
       " 'that',\n",
       " 'we',\n",
       " 'can',\n",
       " 'put',\n",
       " 'interesting',\n",
       " 'things',\n",
       " 'in',\n",
       " 'it',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'have',\n",
       " 'anything',\n",
       " 'in',\n",
       " 'it',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'except',\n",
       " 'some',\n",
       " 'unix',\n",
       " 'software',\n",
       " 'useful',\n",
       " 'for',\n",
       " 'such',\n",
       " 'endeavors',\n",
       " 'sorry',\n",
       " 'guys',\n",
       " 'but',\n",
       " 'nothing',\n",
       " 'that',\n",
       " 's',\n",
       " 'copyrighted',\n",
       " 'goes',\n",
       " 'into',\n",
       " 'it',\n",
       " 'i',\n",
       " 'am',\n",
       " 'planning',\n",
       " 'on',\n",
       " 'setting',\n",
       " 'up',\n",
       " 'a',\n",
       " 'quotation',\n",
       " 'server',\n",
       " 'that',\n",
       " 'can',\n",
       " 'email',\n",
       " 'periodic',\n",
       " 'interesting',\n",
       " 'citations',\n",
       " 'from',\n",
       " 'the',\n",
       " 'principal',\n",
       " 'sources',\n",
       " 'of',\n",
       " 'catholic',\n",
       " 'doctrine',\n",
       " 'not',\n",
       " 'done',\n",
       " 'yet',\n",
       " 'i',\n",
       " 'have',\n",
       " 'obtained',\n",
       " 'permission',\n",
       " 'from',\n",
       " 'the',\n",
       " 'english',\n",
       " 'language',\n",
       " 'publishers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'italian',\n",
       " 'catholic',\n",
       " 'magazine',\n",
       " 'days',\n",
       " 'to',\n",
       " 'take',\n",
       " 'material',\n",
       " 'from',\n",
       " 'their',\n",
       " 'magazine',\n",
       " 'i',\n",
       " 'intend',\n",
       " 'to',\n",
       " 'scan',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'more',\n",
       " 'interesting',\n",
       " 'pictures',\n",
       " 'ever',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'cristero',\n",
       " 'or',\n",
       " 'st',\n",
       " 'pius',\n",
       " 'x',\n",
       " 'and',\n",
       " 'put',\n",
       " 'them',\n",
       " 'in',\n",
       " 'the',\n",
       " 'archives',\n",
       " 'and',\n",
       " 'also',\n",
       " 'post',\n",
       " 'extracts',\n",
       " 'from',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'more',\n",
       " 'interesting',\n",
       " 'articles',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'european',\n",
       " 'magazine',\n",
       " 'and',\n",
       " 'is',\n",
       " 'of',\n",
       " 'generally',\n",
       " 'higher',\n",
       " 'quality',\n",
       " 'than',\n",
       " 'american',\n",
       " 'catholic',\n",
       " 'material',\n",
       " 'in',\n",
       " 'my',\n",
       " 'opinion',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'any',\n",
       " 'questions',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'subscribe',\n",
       " 'etc',\n",
       " 'send',\n",
       " 'email',\n",
       " 'to',\n",
       " 'catholic',\n",
       " 'sarto',\n",
       " 'budd',\n",
       " 'lake',\n",
       " 'nj',\n",
       " 'us',\n",
       " 'received',\n",
       " 'from',\n",
       " 'unknown',\n",
       " 'helo',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'by',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'sat',\n",
       " 'apr',\n",
       " 'received',\n",
       " 'from',\n",
       " 'auditor',\n",
       " 'by',\n",
       " 'content',\n",
       " 'guys',\n",
       " 'com',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'for',\n",
       " 'whitney',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'sat',\n",
       " 'apr',\n",
       " 'date',\n",
       " 'sat',\n",
       " 'apr',\n",
       " 'from',\n",
       " 'stella',\n",
       " 'lowry',\n",
       " 'rookcuduq',\n",
       " 'yahoo',\n",
       " 'com',\n",
       " 'to',\n",
       " 'brian',\n",
       " 'bernice',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'subject',\n",
       " 're',\n",
       " 'date',\n",
       " 'sat',\n",
       " 'apr',\n",
       " 'user',\n",
       " 'agent',\n",
       " 'mutt',\n",
       " 'x',\n",
       " 'mailer',\n",
       " 'mutt',\n",
       " 'x',\n",
       " 'priority',\n",
       " 'normal',\n",
       " 'mime',\n",
       " 'version',\n",
       " 'content',\n",
       " 'type',\n",
       " 'multipart',\n",
       " 'alternative',\n",
       " 'boundary',\n",
       " 'content',\n",
       " 'type',\n",
       " 'text',\n",
       " 'plain',\n",
       " 'content',\n",
       " 'transfer',\n",
       " 'encoding',\n",
       " 'luxury',\n",
       " 'watches',\n",
       " 'buy',\n",
       " 'your',\n",
       " 'own',\n",
       " 'rolex',\n",
       " 'for',\n",
       " 'only',\n",
       " 'rolex',\n",
       " 'cartier',\n",
       " 'bvlgari',\n",
       " 'frank',\n",
       " 'muller',\n",
       " 'patek',\n",
       " 'philippe',\n",
       " 'vacheron',\n",
       " 'constantin',\n",
       " 'a',\n",
       " 'lange',\n",
       " 'sohne',\n",
       " 'audemars',\n",
       " 'piguet',\n",
       " 'jaeger',\n",
       " 'lecoultre',\n",
       " 'iwc',\n",
       " 'officine',\n",
       " 'panerai',\n",
       " 'breitling',\n",
       " 'omega',\n",
       " 'tag',\n",
       " 'heuer',\n",
       " 'exapmle',\n",
       " 'rolex',\n",
       " 'full',\n",
       " 'gold',\n",
       " 'daytona',\n",
       " 'for',\n",
       " 'men',\n",
       " 'only',\n",
       " 'fast',\n",
       " 'delivery',\n",
       " 'the',\n",
       " 'lowest',\n",
       " 'prices',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'worldwide',\n",
       " 'shipping',\n",
       " 'visit',\n",
       " 'our',\n",
       " 'shop',\n",
       " 'at',\n",
       " 'http',\n",
       " 'sewandeatone',\n",
       " 'com',\n",
       " 'received',\n",
       " 'from',\n",
       " 'dhcp',\n",
       " 'kgpt',\n",
       " 'tn',\n",
       " 'charter',\n",
       " 'com',\n",
       " 'helo',\n",
       " 'webmail',\n",
       " 'com',\n",
       " 'psmtp',\n",
       " 'com',\n",
       " 'by',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'wed',\n",
       " 'apr',\n",
       " 'message',\n",
       " 'id',\n",
       " 'vudwwhp',\n",
       " 'from',\n",
       " 'walter',\n",
       " 'trwmpca',\n",
       " 'downtowncumberland',\n",
       " 'com',\n",
       " 'to',\n",
       " 'arline',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'subject',\n",
       " 'take',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'this',\n",
       " 'date',\n",
       " 'tue',\n",
       " 'apr',\n",
       " 'mime',\n",
       " 'version',\n",
       " 'content',\n",
       " 'type',\n",
       " 'text',\n",
       " 'plain',\n",
       " 'format',\n",
       " 'flowed',\n",
       " 'charset',\n",
       " 'iso',\n",
       " 'reply',\n",
       " 'type',\n",
       " 'original',\n",
       " 'content',\n",
       " 'transfer',\n",
       " 'encoding',\n",
       " 'x',\n",
       " 'priority',\n",
       " 'x',\n",
       " 'msmail',\n",
       " 'priority',\n",
       " 'normal',\n",
       " 'x',\n",
       " 'mailer',\n",
       " 'microsoft',\n",
       " 'outlook',\n",
       " 'express',\n",
       " 'x',\n",
       " 'mimeole',\n",
       " 'produced',\n",
       " 'by',\n",
       " 'microsoft',\n",
       " 'mimeole',\n",
       " 'x',\n",
       " 'antivirus',\n",
       " 'avast',\n",
       " 'vps',\n",
       " 'outbound',\n",
       " 'message',\n",
       " 'x',\n",
       " 'antivirus',\n",
       " 'status',\n",
       " 'clean',\n",
       " 'academic',\n",
       " 'qualifications',\n",
       " 'available',\n",
       " 'from',\n",
       " 'prestigious',\n",
       " 'non',\n",
       " 'acc',\n",
       " 'redited',\n",
       " 'uni',\n",
       " 'versities',\n",
       " 'do',\n",
       " 'you',\n",
       " 'have',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'the',\n",
       " 'experience',\n",
       " 'but',\n",
       " 'lack',\n",
       " 'the',\n",
       " 'qualifications',\n",
       " 'are',\n",
       " 'you',\n",
       " 'getting',\n",
       " 'turned',\n",
       " 'down',\n",
       " 'time',\n",
       " 'and',\n",
       " 'time',\n",
       " 'again',\n",
       " 'for',\n",
       " 'the',\n",
       " 'job',\n",
       " 'of',\n",
       " 'your',\n",
       " 'dreams',\n",
       " 'because',\n",
       " 'you',\n",
       " 'just',\n",
       " 'don',\n",
       " 't',\n",
       " 'have',\n",
       " 'the',\n",
       " 'right',\n",
       " 'letters',\n",
       " 'after',\n",
       " 'your',\n",
       " 'name',\n",
       " 'get',\n",
       " 'the',\n",
       " 'prestige',\n",
       " 'that',\n",
       " 'you',\n",
       " 'deserve',\n",
       " 'today',\n",
       " 'move',\n",
       " 'ahead',\n",
       " 'in',\n",
       " 'your',\n",
       " 'career',\n",
       " 'today',\n",
       " 'call',\n",
       " 'bac',\n",
       " 'helors',\n",
       " 'mas',\n",
       " 'ters',\n",
       " 'and',\n",
       " 'ph',\n",
       " 'd',\n",
       " 's',\n",
       " 'available',\n",
       " 'in',\n",
       " 'your',\n",
       " 'field',\n",
       " 'no',\n",
       " 'examinations',\n",
       " 'no',\n",
       " 'classes',\n",
       " 'no',\n",
       " 'textbooks',\n",
       " 'call',\n",
       " 'to',\n",
       " 'register',\n",
       " 'and',\n",
       " 'receive',\n",
       " 'your',\n",
       " 'qual',\n",
       " 'ifications',\n",
       " 'within',\n",
       " 'days',\n",
       " 'hours',\n",
       " 'a',\n",
       " 'day',\n",
       " 'days',\n",
       " 'a',\n",
       " 'week',\n",
       " 'confidentiality',\n",
       " 'assured',\n",
       " 'received',\n",
       " 'from',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'by',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'fri',\n",
       " 'apr',\n",
       " 'received',\n",
       " 'from',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'by',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'fri',\n",
       " 'apr',\n",
       " 'received',\n",
       " 'from',\n",
       " 'localhost',\n",
       " 'by',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'with',\n",
       " 'smtp',\n",
       " 'id',\n",
       " 'fri',\n",
       " 'apr',\n",
       " 'to',\n",
       " 'fans',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'subject',\n",
       " 'greetings',\n",
       " 'date',\n",
       " 'fri',\n",
       " 'apr',\n",
       " 'from',\n",
       " 'scott',\n",
       " 'schwartz',\n",
       " 'schwartz',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'message',\n",
       " 'id',\n",
       " 'groucho',\n",
       " 'cs',\n",
       " 'psu',\n",
       " 'edu',\n",
       " 'greetings',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'to',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf54e29",
   "metadata": {},
   "source": [
    "We split the dataset using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6065d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c9df013",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f3f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.spam_word_count = defaultdict(int)\n",
    "        self.ham_word_count = defaultdict(int)\n",
    "        self.spam_total_words = 0\n",
    "        self.ham_total_words = 0\n",
    "        self.spam_priori = 0\n",
    "        self.ham_priori = 0\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        # our dataframe is already in lowercase, but for future purposes we add this\n",
    "        text = text.lower()\n",
    "        words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "        return words\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        # filter Email data (X) with indices where Class (y) is equal to 1 or spam\n",
    "        spam_messages = X[y == 1]\n",
    "        # filter Email data (X) with indices where Class (y) is equal to 0 or ham\n",
    "        ham_messages = X[y == 0]\n",
    "        \n",
    "        self.spam_priori = len(spam_messages) / len(X)\n",
    "        self.ham_priori = len(ham_messages) / len(X)\n",
    "        \n",
    "        for message in spam_messages:\n",
    "            words = self.preprocess(message)\n",
    "            for word in words:\n",
    "                # update dictionary with word and add value of 1 in value\n",
    "                self.spam_word_count[word] += 1\n",
    "                self.spam_total_words += 1\n",
    "        \n",
    "        for message in ham_messages:\n",
    "            words = self.preprocess(message)\n",
    "            for word in words:\n",
    "                # update dictionary with word and add value of 1 in value\n",
    "                self.ham_word_count[word] += 1\n",
    "                self.ham_total_words += 1\n",
    "    \n",
    "    def predict(self, X, alpha=0):\n",
    "        predictions = []\n",
    "        for message in X:\n",
    "            words = self.preprocess(message)\n",
    "            spam_prob = np.log(self.spam_priori)\n",
    "            ham_prob = np.log(self.ham_priori)\n",
    "            \n",
    "            for word in words:\n",
    "                spam_prob += np.log((self.spam_word_count[word] + alpha) / (self.spam_total_words + len(self.spam_word_count) * alpha))\n",
    "                ham_prob += np.log((self.ham_word_count[word] + alpha) / (self.ham_total_words + len(self.ham_word_count) * alpha))\n",
    "            \n",
    "            if spam_prob > ham_prob:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6cd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eadba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = NaiveBayesClassifier()\n",
    "\n",
    "nb_classifier.train(train_df[\"Email\"].values, train_df[\"Class\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933295d3",
   "metadata": {},
   "source": [
    "Performance metrics with different alpha parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e235d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-2 Accuracy: 0.9543\n",
      "alpha-2 Precision: 0.9896\n",
      "alpha-2 Recall: 0.9412\n",
      "********************\n",
      "alpha-1 Accuracy: 0.9561\n",
      "alpha-1 Precision: 0.9914\n",
      "alpha-1 Recall: 0.9422\n",
      "********************\n",
      "alpha-0.5 Accuracy: 0.9604\n",
      "alpha-0.5 Precision: 0.9924\n",
      "alpha-0.5 Recall: 0.9478\n",
      "********************\n",
      "alpha-0.1 Accuracy: 0.9684\n",
      "alpha-0.1 Precision: 0.9938\n",
      "alpha-0.1 Recall: 0.9584\n",
      "********************\n",
      "alpha-0.005 Accuracy: 0.9766\n",
      "alpha-0.005 Precision: 0.9948\n",
      "alpha-0.005 Recall: 0.9698\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 1, 0.5, 0.1, 0.005]:\n",
    "    \n",
    "    y_pred = nb_classifier.predict(test_df[\"Email\"].values, alpha=i)\n",
    "    \n",
    "    print(\"alpha-{} Accuracy: {:.4f}\".format(i, accuracy_score(test_df[\"Class\"].values, y_pred)))\n",
    "    print(\"alpha-{} Precision: {:.4f}\".format(i, precision_score(test_df[\"Class\"].values, y_pred)))\n",
    "    print(\"alpha-{} Recall: {:.4f}\".format(i, recall_score(test_df[\"Class\"].values, y_pred)))\n",
    "    print(\"*\"*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
